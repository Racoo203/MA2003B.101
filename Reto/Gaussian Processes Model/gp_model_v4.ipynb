{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import gpytorch\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution, LMCVariationalStrategy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run id setup\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "date = '26-08-2024'\n",
    "version = 'v2'\n",
    "run_id = date + '_' + version\n",
    "\n",
    "# Create a folder if it doesn't exist\n",
    "folder_path = f'{run_id}'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuda Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of GPUs available: 1\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if cuda_available else 'cpu')\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "if cuda_available:\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../Dataset/dataset.csv')\n",
    "dataset['Date'] = pd.to_datetime(dataset['Date'])\n",
    "dataset['Day'] = dataset['Date'].dt.day\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "dataset['Year'] = dataset['Date'].dt.year\n",
    "dataset['Weekday'] = dataset['Date'].dt.weekday\n",
    "dataset['Quarter'] = dataset['Date'].dt.quarter\n",
    "dataset['DayOfYear'] = dataset['Date'].dt.dayofyear\n",
    "\n",
    "dataset = dataset.sample(frac=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16464, 16]) torch.Size([16464, 7])\n",
      "torch.Size([4116, 16]) torch.Size([4116, 7])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     28\u001b[0m pollution_dataset_train \u001b[38;5;241m=\u001b[39m TensorDataset(X_train, y_train)\n\u001b[1;32m---> 29\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(pollution_dataset_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "target_vars = ['CO', 'NO', 'NO2', 'NOX', 'O3', 'PM10', 'PM2.5']\n",
    "\n",
    "X = dataset.drop(columns=['Date', 'Nombre_Estacion', 'Clave_Estacion'] + target_vars)  # Adjust columns as needed\n",
    "y = dataset[target_vars]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler_x = StandardScaler()\n",
    "X_train = scaler_x.fit_transform(X_train)\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n",
    "# Scale y\n",
    "scaler_y = StandardScaler()\n",
    "y_train = scaler_y.fit_transform(y_train)\n",
    "y_test = scaler_y.transform(y_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "pollution_dataset_train = TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultitaskGPModel(ApproximateGP):\n",
    "    def __init__(self, num_latents, num_tasks, num_features):\n",
    "        # Let's use a different set of inducing points for each latent function\n",
    "        inducing_points = torch.rand(num_latents, num_features, num_features).to(device)\n",
    "        \n",
    "        # We have to mark the CholeskyVariationalDistribution as batch\n",
    "        # so that we learn a variational distribution for each task\n",
    "        variational_distribution = CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([num_latents])\n",
    "        )\n",
    "        \n",
    "        # We have to wrap the VariationalStrategy in a LMCVariationalStrategy\n",
    "        # so that the output will be a MultitaskMultivariateNormal rather than a batch output\n",
    "        variational_strategy = LMCVariationalStrategy(\n",
    "            gpytorch.variational.VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ),\n",
    "            num_tasks=num_tasks,\n",
    "            num_latents=num_latents,\n",
    "            latent_dim=-1\n",
    "        )\n",
    "\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        # The mean and covariance modules should be marked as batch\n",
    "        # so we learn a different set of hyperparameters\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([num_latents]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([num_latents]), ard_num_dims=num_features),  # Adjust for ARD\n",
    "            batch_shape=torch.Size([num_latents])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # The forward function should be written as if we were dealing with each output\n",
    "        # dimension in batch\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: Trial):\n",
    "    # Suggest hyperparameters to optimize\n",
    "    num_latents = trial.suggest_int('num_latents', 1, 10)  # Vary the number of latent functions\n",
    "    lr = trial.suggest_loguniform('lr', 1e-4, 1e-1)  # Log-uniform sampling for learning rate\n",
    "    batch_size = trial.suggest_categorical('batch_size', [500, 1000, 2000])  # Different batch sizes\n",
    "    \n",
    "    # Redefine your model and optimizer with suggested hyperparameters\n",
    "    model = MultitaskGPModel(num_latents=num_latents, num_tasks=y.shape[-1], num_features=X.shape[-1]).to(device)\n",
    "    likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=y.shape[-1]).to(device)\n",
    "    \n",
    "    model.train()\n",
    "    likelihood.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': model.parameters()},\n",
    "        {'params': likelihood.parameters()},\n",
    "    ], lr=lr)\n",
    "\n",
    "    # Use the same MLL (marginal log likelihood)\n",
    "    mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=y_train.size(0))\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(200):  # Reduce epochs to save time during hyperparameter tuning\n",
    "        for X_batch, y_batch in DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = -mll(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    model.eval()\n",
    "    likelihood.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = likelihood(model(X_test)).mean\n",
    "        y_pred_np = scaler_y.inverse_transform(y_pred.cpu().numpy())\n",
    "        y_test_np = scaler_y.inverse_transform(y_test.cpu().numpy())\n",
    "    \n",
    "    # Calculate the R2 score (or other metrics)\n",
    "    r2 = r2_score(y_true=y_test_np, y_pred=y_pred_np, multioutput='raw_values').mean()  # Average R2 score\n",
    "    \n",
    "    return r2  # Optuna maximizes the objective function, so higher R2 is better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')  # We want to maximize the R2 score\n",
    "study.optimize(objective, n_trials=20)  # Number of trials, adjust based on your time and resources\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f'R2 Score: {trial.value}')\n",
    "print('Best hyperparameters: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_num_latents = study.best_params['num_latents']\n",
    "best_lr = study.best_params['lr']\n",
    "best_batch_size = study.best_params['batch_size']\n",
    "\n",
    "model = MultitaskGPModel(num_latents=best_num_latents, num_tasks=y.shape[-1], num_features=X.shape[-1]).to(device)\n",
    "likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=y.shape[-1]).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "    {'params': likelihood.parameters()},\n",
    "], lr=best_lr)\n",
    "\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, num_data=y_train.size(0))\n",
    "\n",
    "# Training loop with the best parameters\n",
    "for epoch in tqdm(range(500), desc=\"Epoch\"):\n",
    "    for X_batch, y_batch in DataLoader(TensorDataset(X_train, y_train), batch_size=best_batch_size, shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = -mll(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters\n",
    "with open(f'{run_id}/{run_id}_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "with open(f'{run_id}/{run_id}_likelihood.pkl', 'wb') as file:\n",
    "    pickle.dump(likelihood, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{run_id}/{run_id}_model.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "with open(f'{run_id}/{run_id}_likelihood.pkl', 'rb') as file:\n",
    "    likelihood = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = likelihood(model(X_test))\n",
    "y_pred = y_pred.mean\n",
    "y_pred = y_pred.cpu().detach().numpy()\n",
    "\n",
    "y_pred_np = scaler_y.inverse_transform(y_pred)\n",
    "y_test_np = scaler_y.inverse_transform(y_test.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_pred=y_pred_np, y_true=y_test_np, multioutput='raw_values')\n",
    "mae = mean_absolute_error(y_pred=y_pred_np, y_true=y_test_np, multioutput='raw_values')\n",
    "mse = mean_squared_error(y_pred=y_pred_np, y_true=y_test_np, multioutput='raw_values')\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'R2': r2,\n",
    "    'MAE': mae,\n",
    "    'MSE': mse,\n",
    "    'RMSE': rmse\n",
    "}, index=target_vars)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(6*4, 6*2))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(target_vars)):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(y_test_np[:, i], y_pred_np[:, i], alpha=0.5)\n",
    "    ax.set_xlabel('True')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    ax.set_title(target_vars[i])\n",
    "    ax.plot([y_test_np[:, i].min(), y_test_np[:, i].max()], [y_test_np[:, i].min(), y_test_np[:, i].max()], 'k--', lw=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(6*4, 6*2))\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(len(target_vars)):\n",
    "    y_pred_ordered = np.sort(y_pred_np[:, i])\n",
    "    y_pred_ordered = np.insert(y_pred_ordered, 0, 0)\n",
    "    y_pred_lorenz = np.cumsum(y_pred_ordered) / np.sum(y_pred_ordered)\n",
    "\n",
    "    x_vals = np.linspace(0, 1, len(y_pred_lorenz))\n",
    "    \n",
    "    axes[i].plot(x_vals, y_pred_lorenz, label='Lorenz Curve')\n",
    "    axes[i].fill_between(x_vals, 0, y_pred_lorenz, alpha=0.3, color='blue')  # Fill under the Lorenz Curve\n",
    "    axes[i].plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Equality')\n",
    "    axes[i].set_xlabel('Cumulative Share of Population')\n",
    "    axes[i].set_ylabel('Cumulative Share of Data')\n",
    "    axes[i].set_title(f'Lorenz Curve for {target_vars[i]}')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
